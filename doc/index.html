<!doctype html>

<!--[if lt IE 7]><html lang="en-US" class="no-js lt-ie9 lt-ie8 lt-ie7"><![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html lang="en-US" class="no-js lt-ie9 lt-ie8"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html lang="en-US" class="no-js lt-ie9"><![endif]-->
<!--[if gt IE 8]><!-->
<html lang="en-US" class="no-js">
    <!--<![endif]-->

    <head>
        <meta charset="utf-8">

        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <title>Apache Spot (incubating) Documentation</title>

        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1"/>

        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="icon" href="favicon.png">
        <!--[if IE]>
        <link rel="shortcut icon" href="http://spot.incubator.apache.org/favicon.ico">
        <![endif]-->
        <meta name="msapplication-TileColor" content="#f01d4f">
        <meta name="msapplication-TileImage" content="images/win8-tile-icon.png">

        <link rel='dns-prefetch' href='//fonts.googleapis.com' />

        <link rel='stylesheet' id='googleFonts-css'  href='http://fonts.googleapis.com/css?family=Lato%3A400%2C700%2C400italic%2C700italic' type='text/css' media='all' />
        <link rel='stylesheet' href='css/style.css' type='text/css' media='all' />

        <link rel='stylesheet' id='mm-css-css'  href='css/meanmenu.css' type='text/css' media='all' />
        <script type='text/javascript' src='js/libs/modernizr.custom.min.js'></script>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script type='text/javascript' src='js/jquery-migrate.min.js'></script>
        <script type='text/javascript' src='js/jquery.meanmenu.js'></script>

    </head>

    <body>

        <div id="container">
            <header class="header">

                <div id="inner-header" class="wrap cf">

                    <p id="logo" class="h1" itemscope itemtype="http://schema.org/Organization">
                        <a href="http://spot.incubator.apache.org/" rel="nofollow"><img src="images/logo.png" alt="Apache Spot" /></a>
                    </p>
					<div class="desktop">
	                    <nav role="navigation" itemscope itemtype="http://schema.org/SiteNavigationElement">
	                        <ul id="menu-main-menu" class="nav top-nav cf">
	                            <li class="menu-item">
	                                <a target="_blank" href="https://github.com/apache/incubator-spot#try-the-apache-spot-ui-with-example-data">Get Started</a>
	                            </li>
	                            <li class="menu-item">
	                                <a target="_blank" href="https://github.com/apache/incubator-spot.git">Download</a>
	                            </li>
	                            <li class="menu-item">
	                                <a href="http://spot.incubator.apache.org/contribute">Contribute</a>
	                            </li>
	                            <li class="menu-item">
	                                <a href="http://spot.incubator.apache.org/doc/">Documentation</a>
	                            </li>
	                            <li class="menu-item menu-item-has-children">
	                                <a href="#">Project Components</a>
	                                <ul class="sub-menu">
	                                	<li><a href="http://spot.incubator.apache.org/project-components/open-data-models">Open Data Models</a></li>
	                                	<li><a href="http://spot.incubator.apache.org/project-components/ingestion">Ingestion</a></li>
	                                	<li><a href="http://spot.incubator.apache.org/project-components/machine-learning">Machine Learning</a></li>
	                                	<li><a href="http://spot.incubator.apache.org/project-components/visualization">Visualization</a></li>
	                                </ul>
	                            </li>
	                            <li class="menu-item">
	                                <a href="http://spot.incubator.apache.org/blog">Blog</a>
	                            </li>
	                        </ul>
	                    </nav>
                    </div>

                </div>

            </header>

            <div id="mobile-nav"></div>
            
            <div id="masthead"></div>
            
            <div id="mainwrap">
            	<nav class="cbp-spmenu cbp-spmenu-vertical cbp-spmenu-left" id="cbp-spmenu-s1">

            		<button id="showLeft"><span class="menuicon-menu"></span></button>
            		
            		<h3>Documents</h3>
            		<a href="#introduction">Introduction <span class="icon-keyboard_arrow_right"></span></a>
			        <a href="#environment">Environment <span class="icon-keyboard_arrow_right"></span></a>    
			        <a href="#installation" class="sub-menu">Installation <span class="icon-keyboard_arrow_right"></span></a> 
			        <ul>
				        <li><a href="#cdh">CDH Requirements</a></li>
				        <li><a href="#deployment">Deployment</a>  </li>  
				        <li><a href="#configuration">Configuration</a></li>            
				        <li><a href="#ingest">Ingest</a></li> 
				        <li><a href="#ml">Machine Learning</a></li>
				        <li><a href="#oa">OA</a></li> 			        	
			        </ul>      
			        <a href="#userguide" class="sub-menu">User Guide <span class="icon-keyboard_arrow_right"></span></a>
			        <ul>
				        <li><a href="#uflow">Flow</a></li>
				        <li><a href="#udns">DNS</a>  </li>  
				        <li><a href="#uproxy">Proxy</a></li>			        	
			        </ul>

            	</nav>
            	           
			    <div id="main">
			        <div id="introduction">
			            <h1>Introduction</h1>
			            <p>
			                Apache Spot (incubating) is a solution built to leverage strong technology in both &#34;big data&#34; and scientific computing disciplines. While the solution solves problems end-to-end, components may be leveraged individually or integrated into other solutions. All components can output data in CSV format, maximizing interoperability.
			                <br>
			            </p>
			            <img src="images/1.1_technical_overviewv02.jpg" width="95%"><br><br>            
			            <h3>Parallel Ingest Framework.</h3>
			            <p>
			                The system uses decoders optimized from open source, that decodes binary flow and packet data, then loading the data in HDFS and data structures inside Hadoop. The decoded data is stored in multiple formats so it is available for searching, used by machine learning, transfer to law enforcement, or inputs to other systems.
			            </p>
			            <h3>Machine Learning.</h3>
			            <p>
			                The system uses a combination of Apache Spark to run scalable machine learning algorithms. The machine learning component works not only as a filter for separating bad traffic from benign, but also as a way to characterize the unique behavior of network traffic in an organization.
			            </p>
			            <h3>Operational Analytics.</h3>
			            <p>
			                In addition to machine learning, a proven process of context enrichment, noise filtering, whitelisting, and heuristics are applied to network data to produce a short list of the most likely patterns, which may be security threats.<br><br>    
			            </p>
			        </div>
			        <div id="environment">
			            <h1>Environment</h1>
			            <h3>PURE HADOOP</h3>
			            <p>
			                Apache Spot (incubating) can be installed on a new or existing Hadoop cluster, its components viewed as services and distributed according to common roles in the cluster. One approach is to follow the recommended deployment of CDH (see diagram below).<br><br>
			
			                This approach is recommended for customers with a dedicated cluster for use of the solution or a security data lake; it takes advantage of existing investment in hardware and software. The disadvantage of this approach is that it does require the installation of software on Hadoop nodes not managed by systems like Cloudera Manager.<br><br>
			            </p>
			            <img src="images/pure_hadoop.bmp" width="95%"><br><br>
			
			            <p>
			                In the Pure Hadoop deployment scenario, the ingest component runs on an edge node, which is an expected use of this role. It is required to install some non-Hadoop software to make ingest component work. The Operational Analytics runs on a node intended for browser-based management and user applications, so that all user interfaces are located on a node or nodes with the same role. The Machine Learning (ML) component is installed on worker nodes, as the resource management for an ML pipeline is similar for functions inside and outside Hadoop.<br><br>
			
			                Although both of these deployment options are validated and supported, additional scenarios that combine these approaches are certainly <br><br>    
			            </p>
			            <h3>Hybrid Hadoop</h3>
			
			            <p>
			                On existing Hadoop installations, a different approach involves using additional virtual machines and interacting with Hadoop components (Spark, HDFS) through a gateway node. This approach is recommended for customers with a Hadoop environment hosting heterogeneous use cases, where minimal deviation from node roles is desired. The disadvantage is that virtual machines must be sized properly according to workloads.<br><br>
			            </p>
			            <img src="images/hybrid_hadoop.bmp" width="95%"><br><br>
			
			            <p>
			                In addition to the services deployed on the existing cluster, additional Virtual Machines (VMs) are required to host the non-Hadoop functions of the solution. The gateway service is required for some of these VMs to allow for interaction with Spark, Hive, and HDFS.<br><br>
			            </p>
			
			            <b>Note:</b> While the above condition is a recommended layout for production, pilot deployments may be chosen to combine the above roles into fewer VMs. Each component of the Apache Spot (incubating) solution has integral interactions with Hadoop, but its non-Hadoop processing and memory requirements are separable with this approach.<br><br>
			
			        </div>
			        <div id="installation">
			            <h1>Installation</h1>
			            <div id="cdh">
			                
			                    This installation guide assumes that a cluster with HDFS is running CDH.<br>
			                    <h2>1. CDH (Cloudera Distribution of Hadoop) Requirements:</h2>
			                    <b>Minimum required version:</b> 5.4<br>
			                    <b>NOTE:</b> Spot requires spark 1.6, if you are using CDH < 5.7 please upgrade your spark version to 1.6.
			                    <h3>Required Hadoop Services before install apache spot (incubating):</h3>
			                    <ol>                
			                        <li>HDFS.</li>
			                        <li>HIVE.</li>
			                        <li>IMPALA.</li>
			                        <li>KAFKA.</li>
			                        <li>SPARK (YARN).</li>
			                        <li>YARN.</li>
			                        <li>Zookeeper.</li>                
			                    </ol>                
			            </div>
			            <div id="deployment">
			                <h2>2. Deployment Recommendations</h2>
			                There are four components in apache spot (incubating):
			                <ul>
			                    <li><b>spot-setup</b> &mdash;  scripts that create the required HDFS paths, hive tables and configuration for apache spot (incubating).</li>
			                    <li><b>spot-ingest</b> &mdash;  binary and log files are captured or transferred into the Hadoop cluster, where they are transformed and loaded into solution data stores.</li>
			                    <li><b>spot-ml</b> &mdash;  machine learning algorithms are used to add additional learning information to the ingest data, which is used to filter and sort raw data.</li>
			                    <li><b>spot-oa</b>&mdash;  data output from the machine learning component is augmented with context and heuristics, then is available to the user for interacting with it.</li>
			                </ul> 
			                While all of the components can be installed on the same server in a development or test scenario, the recommended configuration for production is to map the components to specific server roles in a Hadoop cluster.<br><br>
			                <table class="configuration">
			                    <tr>
			                        <th>Component</th>
			                        <th>Node</th>
			                    </tr>
			                    <tr>
			                        <td>spot-setup</td>
			                        <td>Edge Server (Gateway)</td>
			                    </tr>
			                    <tr>
			                        <td>spot-ingest</td>
			                        <td>Edge Server (Gateway)</td>
			                    </tr>
			                    <tr>
			                        <td>spot-ml</td>
			                        <td>YARN Node Manager</td>
			                    </tr>
			                    <tr>
			                        <td>spot-oa</td>
			                        <td>Node with Cloudera Manager</td>
			                    </tr>
			                </table>
			            </div>
			            <div id="configuration">
			                <h2>3. Configuring the cluster.</h2>
			                <h3>3.1 Create a user account for apache spot (incubating).</h3>
			                <p>
			                    Before starting the installation, 
			                    the recommended approach is to create a user account with super user privileges (sudo) 
			                    and with access to HDFS in each one of the nodes where apache spot (incubating) is going to be installed ( i.e. edge server, yarn node).<br>
			                </p>
			
			                <b>Add user to all apache spot (incubating) nodes:</b><br><br>
			                <p class="terminal"> 
			                    sudo adduser &#60;solution-user&#62;<br>
			                    passwd &#60;solution-user&#62;
			                </p><br>
			
			                <b>Add user to HDFS supergroup (IMPORTANT: this should be done in the Name Node) :</b><br><br>
			                <p class="terminal">
			                    sudo usermod -G supergroup $username
			                </p><br>
			
			                <h3>3.2 Get the code.</h3>
			                Go to the home directory of the solution user in the node assigned for spot-setup and spot-ingest and clone the code:<br><br>
			                <p class="terminal">
			                    git clone https://github.com/apache/incubator-spot.git
			                </p><br>
			
			                <h3>3.3 Edit apache spot (incubating) configuration.</h3>
			                Go to apache spot (incubating) configuration module to edit the solution configuration:<br><br>
			                <p class="terminal">
			                    cd /home/solution_user/incubator-spot/spot-setup<br>
			                    vi spot.conf
			                </p><br>
			                
			                Configuration variables of apache spot (incubating):<br><br>
			                <table class="configuration">
			                    <tr>
			                        <th>Key</th>
			                        <th>Value</th>
			                        <th>Need to be edited</th>   
			                    <tr>
			                            <td>NODES</td>
			                            <td style="text-align:left">A space delimited list of the Data Nodes that will run the C/MPI part of the pipeline. Be very careful to keep * the variable in the format (&#39;host1&#39; &#39;host2&#39; &#39;host3&#39; ...). The first node is the same node as the MLNODE.</td>
			                            <td>No (deprecated)</td>
			                    </tr>
			                    <tr>
			                            <td>UINODE</td>
			                            <td style="text-align:left">The node that runs the spot-oa (aka, user interface node).</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>MLNODE</td>
			                            <td style="text-align:left">The node that runs spot-ml, controlling the other nodes. The MLNODE must be the first node in the NODES list</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>GWNODE</td>
			                            <td style="text-align:left">The node that runs the spot-ingest (ingest process)</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>DBNAME</td>
			                            <td style="text-align:left">The name of the database used by the solution (i.e. spotdb)</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>HUSER</td>
			                            <td style="text-align:left">HDFS user path that will be the base path for the solution; this is usually the same user that you created to run the solution (i.e. /user/&#34;solution-user&#34;</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>DSOURCES</td>
			                            <td style="text-align:left">Data sources enabled in this installation</td>
			                            <td>No (deprecated)</td>
			                    </tr>
			                    <tr>
			                            <td>DFOLDERS</td>
			                            <td style="text-align:left">Built-in paths for the directory structure in HDFS</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>DNS_PATH</td>
			                            <td style="text-align:left">The path to the DNS records in Hive; this will be dynamically built within the pipeline with values for No ${YR}, ${MH} and ${DY}</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>PROXY_PATH</td>
			                            <td style="text-align:left">The path to the proxy records in Hive; this will be dynamically built within the pipeline with values for ${YR}, ${MH} and ${DY}</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>FLOW_PATH</td>
			                            <td style="text-align:left">The path to the flow records in Hive; this will be dynamically built within the pipeline with values for ${YR}, ${MH} and ${DY}</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>HPATH</td>
			                            <td style="text-align:left">Path where output from the ML analysis will be stored</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>IMPALA_DEM</td>
			                            <td style="text-align:left">Node where the impala demon is running, this value can be gotten from Cloudera Manager -> Impala Yes service -> Instances.</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>KRB_AUTH</td>
			                            <td style="text-align:left">(default: false) Turn Kerberos authentication features on/off</td>
			                            <td>Only if Kerberos is enable</td>
			                    </tr>
			                    <tr>
			                            <td>KINITPATH</td>
			                            <td style="text-align:left">Path to the kinit binary file</td>
			                            <td>Only if Kerberos is enable</td>
			                    </tr>
			                    <tr>
			                            <td>KINITOPTS</td>
			                            <td style="text-align:left">Additional options to the kinit command</td>
			                            <td>Only if Kerberos is enable</td>
			                    </tr>
			                    <tr>
			                            <td>KEYTABPATH</td>
			                            <td style="text-align:left">Keytab file path</td>
			                            <td>Only if Kerberos is enable</td>
			                    </tr>
			                    <tr>
			                            <td>KRB_USER</td>
			                            <td style="text-align:left">Kerberos user</td>
			                            <td>Only if Kerberos is enable</td>
			                    </tr>
			                    <tr>
			                            <td>LUSER</td>
			                            <td style="text-align:left">The local filesystem path for the solution, &#34;/home/solution-user/&#34;</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>LPATH</td>
			                            <td style="text-align:left">The local path for the ML intermediate and final results, dynamically built when the pipeline runs</td>
			                            <td>No</td>
			                    </tr>
			                    <tr>
			                            <td>RPATH</td>
			                            <td style="text-align:left">The path on the Operational Analytics node where the pipeline output will be delivered</td>
			                            <td>No (deprecated)</td>
			                    </tr>
			                    <tr>
			                            <td>LDAPATH</td>
			                            <td style="text-align:left">Path to the directory containing the lda code executable and configuration files.</td>
			                            <td>No (deprecated)</td>
			                    </tr>
			                    <tr>
			                            <td>LIPATH</td>
			                            <td style="text-align:left">Local ingest path</td>
			                            <td>No (deprecated)</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_EXEC</td>
			                            <td style="text-align:left">Number if Spark executors</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_EXEC_MEM</td>
			                            <td style="text-align:left">Total memory per executor</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_DRIVER_MEM</td>
			                            <td style="text-align:left">Total driver memory</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_DRIVER_MAX_RESULTS</td>
			                            <td style="text-align:left">Total memory for driver max results</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_EXEC_CORES</td>
			                            <td style="text-align:left">Number of cores per executor</td>
			                            <td>Yes</td>
			                    </tr>
			                    <tr>
			                            <td>SPK_DRIVER_MEM_OVERHEAD</td>
			                            <td style="text-align:left">Driver memory overhead</td>
			                            <td>Yes</td>
			                    </tr>  
			                    <tr>
			                            <td>SPRK_EXEC_MEM_OVERHEAD</td>
			                            <td style="text-align:left">Executor memory overhead</td>
			                            <td>Yes</td>
			                    </tr> 
			                    <tr>
			                            <td>TOL</td>
			                            <td style="text-align:left">Results threshold</td>
			                            <td>No</td>
			                    </tr>           
			                </table>
			                <br><br>
			                <b>NOTE: deprecated keys will be removed in the next releases.</b><br>
			                <b>More details about how to set up Spark properties please go to: <a href="https://github.com/apache/incubator-spot/blob/master/spot-ml/SPARKCONF.md">Spark Configuration</a></b><br><br>
			                
			                <h3>3.4 Run spot-setup.</h3>
			                Copy the configuration file edited in the previous step to &#34;/etc/&#34; folder.<br>
			                <p class="terminal">
			                    sudo cp spot.conf /etc/.    
			                </p><br>
			
			                Copy the configuration to the two nodes named as UINODE and MLNODE.<br>
			                <p class="terminal">
			                    sudo scp spot.conf solution_user@node:/etc/.
			                </p><br>
			
			                Run the hdfs_setup.sh script to create folders in Hadoop for the different use cases (flow, DNS or Proxy), create the Hive database, and finally execute hive query scripts that creates Hive tables needed to access netflow, DNS and proxy data.
			                <p class="terminal">
			                    ./hdfs_setup.sh
			                </p><br>
			
			            </div>
			            <div id="ingest">
			                <h2>4 Ingest.</h2>
			                <h3> 4.1 Ingest Code.</h3>
			                <p>
			                    Copy the ingest folder (spot-ingest) to the selected node for ingest process (i.e. edge server). If you cloned the code in the edge server and you are planning to use the same server for ingest you dont need to copy the folder.
			                </p>
			
			                <h3>4.2 Ingest dependencies.</h3>
			                <ul>
			                    <li>
			                        Create a src folder to install all the dependencies.<br>
			                        <p class="terminal">
			                            cd spot-ingest <br>
			                            mkdir src <br>
			                            cd src <br>
			                        </p><br>
			                    </li>
			                    <li>
			                        Install pip &#45; python package manager.<br>
			                        <p class="terminal">
			                            wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py <br>
			                            sudo -H python get-pip.py
			                        </p><br>
			                    </li>
			                    <li>
			                        kafka-python (how to install) -- Python client for the Apache Kafka distributed stream processing system.<br>
			                        <p class="terminal">
			                            sudo -H pip install kafka-python
			                        </p><br>
			                    </li>
			                    <li>
			                        watchdog - (how to install) Python API library and shell utilities to monitor file system events.<br>
			                        <p class="terminal">
			                            sudo -H pip install watchdog
			                        </p><br>
			                    </li>
			                    <li>
			                        spot-nfdump - netflow dissector tool. This version is a custom version developed for apache spot (incubating) that has special features required for spot-ml.<br>
			                        <p class="terminal">
			                            sudo yum -y groupinstall "Development Tools"<br>
			                            git clone https://github.com/Open-Network-Insight/spot-nfdump.git <br>
			                            cd spot-nfdump<br>
			                            ./install_nfdump.sh<br>
			                            cd ..
			                        </p><br>
			                    </li>
			                    <li>
			                        tshark - DNS dissector tool. For tshark, follow the steps on the web site to install it. Tshark must be downloaded and built from 
			                        <a href="https://www.wireshark.org/download.html"> Wireshark page</a><br>
			                        Full instructions for compiling Wireshark can be found <a href="https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallUnixBuild.html">here</a> instructions for compiling<br>
			                        <p class="terminal">
			                            sudo yum -y install gtk2-devel gtk+-devel bison qt-devel qt5-qtbase-devel sudo yum -y groupinstall "Development Tools"<br>
			                            sudo yum -y install libpcap-devel<br>
			                            #compile Wireshark<br>
			                            wget https://1.na.dl.wireshark.org/src/wireshark-2.2.3.tar.bz2 tar xvf wireshark-2.0.1.tar.bz2<br>
			                            cd wireshark-2.0.1<br>
			                            ./configure --with-gtk2 --disable-wireshark<br>
			                            make<br>
			                            sudo make install<br>
			                            cd ..<br>
			                        </p><br>
			                    </li>
			                    <li>
			                        screen -- The screen utility is used to capture output from the ingest component for logging, troubleshooting, etc. You can check if screen is installed on the node.<br>
			                        <p class="terminal">
			                            which screen
			                        </p><br>
			                        If screen is not available, install it.
			                        <p class="terminal">
			                            sudo yum install screen
			                        </p><br>
			                    </li>
			                    <li>
			                        Spark-Streaming – Download the following jar file: spark-streaming-kafka-0-8-assembly_2.11. This jar adds support for Spark Streaming + Kafka and needs to be downloaded on the following path: spot-ingest/common (with the same name). 
			                        <b>Currently spark streaming is only enabled for proxy pipeline, if you are not planning to ingest proxy data you can skip this step.</b><br>
			                        <p class="terminal">
			                            cd spot-ingest/common<br>
			                            wget https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka- 0-8-assembly_2.11/2.0.0/spark-streaming-kafka-0-8-assembly_2.11-2.0.0.jar
			                        </p><br>
			                    </li>
			                </ul>
			
			                <h3>4.3 Ingest configuration.</h3>
			                Ingest Configuration:<br>
			                The file ingest_conf.json contains all the required configuration to start the ingest module
			                <ul>
			                    <li><b>dbname:</b> Name of HIVE database where all the ingested data will be stored in avro-parquet format.</li>
			                    <li><b>hdfs_app_path:</b> Application path in HDFS where the pipelines will be stored (i.e /user/application_user/).</li>
			                    <li><b>kafka:</b> Kafka and Zookeeper server information required to create/listen topics and partitions.</li>
			                    <li><b>collector_processes:</b> Ingest framework uses multiprocessing to collect files (different from workers), this configuration key defines the numbers of collector processes to use.</li>
			                    <li><b>spark-streaming:</b> Proxy pipeline uses spark streaming to ingest data, this configuration is required to setup the spark application for more details please check : how to configure spark</li>
			                    <li><b>pipelines:</b> In this section you can add multiple configurations for either the same pipeline or different pipelines. The configuration name must be lowercase without spaces (i.e. flow_internals).</li>
			                    <li><b>local_staging:</b> (for each pipeline) this path is very important, ingest uses this for tmp files</li>
			                </ul>
			                For more information about spot ingest please go to <a href="https://github.com/apache/incubator-spot/tree/master/spot-ingest"> spot-ingest</a><br>
			            </div>
			            <div id="ml">
			
			                <h2>5. Machine Learning.</h2>
			                <h3>5.1 ML code.</h3>
			                Copy ML code to the primary ML node, the node will launch Spark application.
			                <p class="terminal">
			                    scp -r spot-ml "ml-node":/home/"solution-user"/. ssh "ml-node"
			                    mv spot-ml ml
			                    cd /home/"solution-user"/ml
			                </p><br>
			
			                <h3>5.1 ML dependencies</h3>
			                <ul>
			                    <li>
			                        Create a src folder to install all the dependencies.
			                        <p class="terminal">
			                            mkdir src<br>
			                            cd src
			                        </p><br>
			                    </li>
			                    <li>Install sbt -- In order to build Scala code, a SBT installation is required. Please download and install <a href="http://www.scala-sbt.org/download.html">download.</a></li>
			                    <li>
			                        Build Spark application.                
			                        <p class="terminal">
			                            cd ml<br>
			                            sbt assembly
			                        </p><br>
			                    </li>
			                </ul>
			
			                <b>NOTE: validate spot.conf is already copied to this node in the following path: /etc/spot.conf</b>
			            </div>
			            <div id="oa">
			                <h2>6. Operational Analytics.</h2>
			                <h3>6.1 OA code.</h3>
			
			                Copy spot-oa code to the OA node designed in the configuration file (UINODE).
			                <p class="terminal">
			                    scp -r spot-oa "ml-node":/home/"solution-user"/. <br>
			                    ssh "oa-node"<br>
			                    cd /home/"solution-user"/spot-oa    
			                </p><br>
			
			                <h2>6.2 OA prerequisites.</h2>
			                In order to execute this process there are a few prerequisites:
			                <ul>
			                    <li>Python 2.7.</li>
			                    <li>spot-ml results. Operational Analytics works and transforms Machine Learning results. The
			                        implementation of Machine Learning in this project is through spot-ml. Although the Operational Analytics is prepared to read csv files and there is not a direct dependency between spot-oa and spot-ml, it's highly recommended to have these two pieces set up together. If users want to implement their own machine learning piece to detect suspicious connections they need to refer to each data type module to know more about input format and schema.</li>
			                    <li><a href="https://pypi.python.org/pypi/tld/0.7.6"> TLD 0.7.6</a></li>
			                </ul>
			
			                <h3>6.3 OA (backend) installation.</h3>
			                OA installation consists of the configuration of extra modules or components and creation of a set of files. Depending on the data type that is going to be processed some components are required and other components are not. If users are planning to analyze the three data types supported (Flow, DNS and Proxy) then all components should be configured.
			                <ol>
			                    <li>Add context files. Context files should go into spot-oa/context folder and they should contain network and geo localization context. For more information on context files go to spot- oa/context/
			                        <a href="https://github.com/apache/incubator-spot/blob/master/spot-oa/README.md">README.md</a><br><br></li>
			                    <li>
			                        Add a file ipranges.csv: Ip ranges file is used by OA when running data type Flow. It should contain a list of ip ranges and the label for the given range, example:
			                        <p class="terminal">
			                            10.0.0.1,10.255.255.255,Internal
			                        </p><br>    
			                    </li>
			                    <li>
			                        Add a file iploc.csv: Ip localization file used by OA when running data type Flow. Create a csv file with ip ranges in integer format and give the coordinates for each range.<br><br>
			                    </li>
			                    <li>
			                        Add a file networkcontext_1.csv: Ip names file is used by OA when running data type DNS and Proxy. This file should contains two columns, one for Ip the other for the name, example:
			                        <p class="terminal">
			                            10.192.180.150, AnyMachine <br>
			                            10.192.1.1, MySystem
			                        </p><br>
			                    </li>
			                    <li>
			                        The spot-setup project contains scripts to install the hive database and also includes the main configuration file for this tool. The main file is called spot.conf which contains different variables that the user can set up to customize their installation. Some variables must be     updated in order to have spot-ml and spot-oa working.<br><br>
			                        To run the OA process it's required to install spot-setup. If it's already installed just make sure the following configuration are set up in spot.conf file (oa node).<br><br>
			                        <b>LUSER:</b> represents the home folder for the user in the Machine Learning node. It's used to know where to return feedback.<br>
			                        <b>HUSER:</b> represents the HDFS folder. It's used to know from where to get Machine Learning results.<br>
			                        <b>IMPALA_DEM:</b> represents the node running Impala daemon. It's needed to execute Impala queries in the OA process.<br>
			                        <b>DBNAME:</b> Hive database, the name is required for OA to execute queries against this database. LPATH: represents the local path where the feedback is going to be sent, it actually works with LUSER.<br><br>
			                    </li>
			                    <li>
			                        Configure components. Components are python modules included in this project that add context and details to the data being analyzed. There are five components and while not all components are required to every data type, it's recommended to configure all of them in case new data types are analyzed in the future. For more details about how to configure each component go to <a href="https://github.com/apache/incubator-spot/blob/master/spot-oa/oa/components/README.md">spot-oa/oa/components/README.md.</a><br><br>
			                    </li>
			                    <li>
			                        You need to update the engine.json file accordingly:
			                        <p class="terminal">
			                            {
			                                "oa_data_engine":"<database engine>",
			                                "impala":{
			                                    "impala_daemon":"<node>"
			                                },
			                                "hive":{}
			                            }
			                        </p><br>
			                        Where:
			                        <ul>
			                            <li>: Whichever database engine you have installed and configured in your cluster to work with Apache Spot (incubating). i.e. "Impala" or "Hive". For this key, the value you enter needs to match exactly with one of the following keys, where you'll need to add the corresponding node name.<br></li>
			                            <li>: The node name in your cluster where you have the database service running.</li>
			                        </ul>
			                    </li>            
			                </ol>
			                For more information please go to: <a href="https://github.com/apache/incubator-spot/blob/master/spot-oa/oa/INSTALL.md"> https://github.com/apache/incubator-spot/blob/master/spot-oa/oa/INSTALL.md</a>
			
			                <h2>6.4 Visualization.</h2>
			                <p>
			                    Apache Spot (incubating) - User Interface (aka Spot UI or UI) Provides tools for interactive visualization, noise filters, white listing, and attack heuristics.<br><br>
			                    Here you will find instructions to get Spot UI up and running. For more information about Spot look here.<br><br>
			                </p>
			
			                <h2>6.5 Visualization requirements.</h2>
			                <ul>
			                    <li>IPython with notebook module enabled (== 3.2.0) <a href="https://ipython.org/ipython-doc/3/index.html"> link</a></li>
			                    <li>NPM - Node Package Manager <a href="https://www.npmjs.com"> link</a></li>
			                    <li>spot-oa output > Spot UI takes any output from spot-oa backend, as input for the visualization tools provided. Please make sure there are files available under PATH_TO_SPOT/ui/data/${PIPELINE}/${DATE}/</li>
			                </ul>
			
			                <h2>6.6 Install visualization.</h2>
			                <ol>
			                    <li>
			                        Go to Spot UI folder:
			                        <p class="terminal">cd spot-oa/ui</p><br>
			                    </li>
			                    <li>
			                        With root privileges, install browserify and uglify as global commands on your system.
			                        <p class="terminal">npm install –g browserify uglifyjs</p><br>
			                    </li>
			                    <li>
			                        Install dependencies and build Spot UI.
			                        <p class="terminal">npm install</p><br>
			                    </li>
			                </ol>
			            </div>
			        </div>
			        <div id="userguide">
			            <h1>User Guide</h1>
			            <div id="uflow">
			                <h2>Flow</h2>
			                <div id="fsc">
			                    <h3>Suspicious Connects</h3>
			                    <p>
			                        Access the analyst view for Suspicious Connects <b>http://"server-ip":8889/files/ui/flow/suspicious.html</b> . 
			                        Select the date that you want to review (defaults to current date). <br>
			                        Your view should look similar to the one below:<br><br>
			                    </p>
			                    <img src="images/1.1sc1.jpg">
			                    <p>
			                        Suspicious Connects Web Page contains 4 frames with different functions and information:
			
			                        <ul>
			                            <li>Suspicious</li>
			                            <li>Network View</li>
			                            <li>Notebook</li>
			                            <li>Details</li>                 
			                        </ul>
			                    </p>
			
			                    <h3>The Suspicious frame</h3>
			                    <p>
			                        Located in the top left corner of the Suspicious Connects Web Page, this frame presents the Top 250 Suspicious Connections in a table format based on Machine Learning (ML) output. These are the columns depicted in this table:
			                        <ul>
			                            <li>Rank - ML output rank</li>
			                            <li>Time - Time received field for Netflow record</li>
			                            <li>Source IP - Netflow Record Source IP Address</li>
			                            <li>Destination IP - Netflow Record Destination IP Address</li>
			                            <li>Source Port - Netflow Record TCP/UDP Source Port Number</li>
			                            <li>Destination Port - Netflow Record TCP/UDP Destination Port Number</li>
			                            <li>Protocol - Text format for Protocol contained within Netflow Record (Ex. TCP/UDP)</li>
			                            <li>Input Packets - Reported Input Packets for the Netflow Record</li>
			                            <li>Input Bytes - Reported Input Bytes for the Netflow Record</li>                        
			                        </ul>
			                    </p>
			                    <p>
			                        <b>Additional functionality in Suspicious frame</b>
			                        <ol>                        
			                            <li>
			                                By selecting a specific row within the Suspicious frame, the connection in the Network View will be highlighted.<br><br>
			                                <img src="images/1.1_sc2.jpg"><br><br>
			                            </li>
			                            <li>
			                                In addition, by performing this row selection the Details Frame presents all the Netflow records in between Source & Destination IP Addresses that happened in the same minute as the Suspicious Record selected<br><br>
			                                <img src="images/1.1_sc3.jpg"><br><br>
			                            </li>
			                            <li>
			                                Next to a Source/Destination IP Addresses, a shield icon might be present. This icon denotes any reputation services value context added as part of the Operational Analytics component. By rolling over you can see the IP Address Reputation result<br><br>
			                                <img src="images/1.1_sc4.jpg"><br><br>
			                            </li>
			                            <li>
			                                An additional icon next to the IP addresses within the Suspicious frame is the globe icon. This icon denotes Geo-localization information context added as part of the Operational Analytics component. By rolling over you can see the additional information<br><br>
			                                <img src="images/1.1_sc5.jpg"><br><br>
			                            </li>
			                        </ol>
			                    </p>
			                    
			                    <h3>The Network View frame</h3>
			                    <p>
			                        Located at the top right corner of the Suspicious Connects Web Page. It is a graphical representation of the Suspicious records relationships. 
			                        If context has been added, Internal IP Addresses will be presented as diamonds and External IP Addresses as circles.<br><br>
			                    </p>
			                    <img src="images/1.1_sc6.jpg"><br><br>
			                    <p>
			                        <b>Additional functionality in Network View frame</b>
			                        <ol>                        
			                            <li>
			                                As soon as you move your mouse over a node, a dialog shows IP address information of that particular node.<br><br>
			                                <img src="images/1.1_sc7.jpg"><br><br>
			                            </li>
			                            <li>
			                                A primary mouse click over one of the nodes will bring a chord diagram into the Details frame. 
			                                The chord diagram is a graphical representation of the connections between the selected node and other nodes within Suspicious Connects records, 
			                                providing number of Bytes From & To. You can move your mouse over an IP to get additional information. In addition, 
			                                drag the chord graph to change its orientation.<br><br>
			                                <img src="images/1.1_sc8.jpg"><br><br>
			                            </li>
			                            <li>
			                                A secondary mouse click uses the node information in order to apply an IP filter to the Suspicious Web Page.<br><br>
			                                <img src="images/1.1_sc9.jpg"><br><br>
			                            </li>                
			                        </ol>
			                    </p>
			
			                    <h3>The Notebook frame</h3>
			                    <p>
			                        This frame contains an initialized Jupyter Notebook. The main function is to allow the Analyst to score IP Addresses and Ports with different values. 
			                        In order to assign a risk to a specific connection, select it using a combination of all the combo boxes, 
			                        select the correct risk rating (1=High risk, 2 = Medium/Potential risk, 3 = Low/Accepted risk) and click Score button. 
			                        Selecting a value from each list will narrow down the coincidences, therefore if the analyst wishes to score all connections with one same relevant attribute (i.e. src port 80), 
			                        then select only the combo boxes that are relevant and leave the rest at the first row at the top.
			                    </p>
			                    <img src="images/1.1_sc10.jpg"><br><br>
			
			                    <h3>The Score button</h3>
			                    <p>
			                        When the Analyst clicks on the Score button, the action will find all coincidences exactly matching the selected values and update their score to the rating selected in the radio button list.
			                    </p>
			
			                    <h3>The Save button</h3>
			                    <p>
			                        Analysts must use Save button in order to store the scored connections. After you click it, the rest of the frames in the page will be refreshed and the connections that you already scored will disappear on the suspicious connects page, including from the lists in the notebook. This will also reorder the flow_scores.csv file to move all scored connections to the end of the file and sort the rest by severity value. A shell script will be executed to copy the file with the scored connections to the ML Node and specific path. The following values will be obtained from the .conf file:
			
			                        <ul>
			                            <li>LPATH</li>
			                            <li>MLNODE</li>
			                            <li>LUSER</li>
			                        </ul>
			
			                        For this process to work correctly, it's important to create an ssh key to enable secure communication between nodes, in this case, the ML node and the node where the UI runs. To learn more on how to create and copy the ssh key, please refer to the "Configure User Accounts" section.
			                    </p>
			
			                    <h3>The Quick IP Scoring box</h3>
			                    <p>
			                        This box allows the Analyst to enter an IP Address and scored using the "Score" and "Save" buttons using the same process depicted above
			                    </p>
			
			                    <h3>Suspicious Connects Web Page Input files</h3>
			                    <ul>
			                            <li>flow_scores.csv</li>
			                            <li>flow_scores_bu.csv</li>               
			                    </ul>
			                </div>
			                <div id="fti">
			                    <h3>Threat Investigation</h3>
			                    <p>
			                        Access the analyst view for suspicious connects <b>http://"server-ip":8889/files/ui/flow/suspicious.html.</b>
			                         Select the date that you want to review. <br>
			                        Your screen should now look like this:<br><br>
			                        <img src="images/1.1sc1.jpg"><br><br>
			                        
			                        The analyst must score the suspicious connections before moving into Threat Investigation View, 
			                        please refer to <a href="#fsc">Suspicious Connects Analyst View</a> walk-through <br>
			                        Select <b>Flows > Threat Investigation </b> from apache spot (incubating) Menu.<br><br>
			                        <img src="images/1.1_ti01.jpg"><br><br>
			
			                        <b>Threat Investigation</b> Web Page will be opened, loading the embedded Jupyter notebook.<br><br>
			                        <img src="images/1.1_ti02.jpg"><br><br>
			
			                        <h3>Expanded search</h3>
			                        <p>
			                            You can select any IP from the list and click <b>Search</b> to view specific details about it. A query to the flow table will be executed looking into the raw data initially collected to find all communication between this and any other IP Addresses during the day, collecting additional information, such as:
			
			                            <ul>
			                                <li>max & avg number of bytes sent/received</li>
			                                <li>max & avg number of packets sent/received</li>
			                                <li>destination port</li>
			                                <li>source port</li>
			                                <li>first & last connection time</li>
			                                <li>count of connections</li>
			                            </ul>
			
			                            The full output of this query is stored into the ir-<ip>.csv file. If an expanded search was previously executed on this IP, the system will extract the results from the preexisting file to reduce the execution time by avoiding another query to the table. Query execution time is long and will vary depending on whether Hive or Impala is being used.<br><br>
			
			                            Based on the results in this file, the following functions will be executed:<br><br>
			                            
			                            <ul>
			                                <li>get_in_out_and_twoway_conns</li>
			                                <li>add_geospatial_info()</li>
			                                <li>add_network_context()</li>
			                            </ul>
			
			                            The system will create three dictionaries, each containing:<br><br>
			                            <ul>
			                                <li>Inbound connections (when the suspicious IP acts only as destination)</li>
			                                <li>Outbound connections (when the suspicious IP acts only as source)</li>
			                                <li>2Way Connections (when the suspicious IP acts as both source and destination)</li>
			
			                             </ul>
			
			                            If an iploc.csv file is available, each dictionary will be updated with the geolocation data for each IP.<br>
			                            If a network_context_1.txt file is available, a description for each identified node will also be added to each dictionary.<br><br>
			
			                            The connections dictionary will be separated into two smaller dictionaries, each containing<br><br>
			                            <ul>
			                                <li>Top 'n' IP's per number of connections.</li>
			                                <li>Top 'n' IP's per bytes transferred.</li>
			                                <li>The number of results stored in the dictionaries (n) can be set by updating the value of the top_results variable.</li>
			                            </ul>
			                        </p>
			
			                        <h3>Save Comments</h3>
			                        <p>
			                            In addition, a web form is displayed under the title of 'Threat summary', 
			                            where the analyst can enter a Title & Description on the kind of attack/behavior described by the particular IP address that is under investigation.<br><br>
			                            Click on the Save button after entering the data to write it into a CSV file, which eventually will be used in the Storyboard Analyst View.<br><br>
			                            <img src="images/1.1_ti03.jpg"><br><br>
			                        </p>
			
			                        <p>
			                            After creating the csv file with the analysis description, 
			                            the following functions will generate all graphs and diagrams related to the IP under investigation, 
			                            to populate the Storyboard Analyst view.<br><br>
			
			                            <ul>
			                                <li>generate_attack_map_file(anchor_ip, top_inbound_b, outbound, twoway)</li>
			                                <li>generate_stats(anchor_ip, top_inbound_b, outbound, twoway, threat_name)</li>
			                                <li>generate_dendro(anchor_ip, top_inbound_b, outbound, twoway, date)</li>
			                                <li>details_inbound(anchor_ip,top_inbound_b)</li>
			                            </ul>
			
			                            <b>generate_attack_map_file()</b> - create a globe map indicating the trajectory of the connections based on their geolocation. 
			                            This function depends on having geolocation data for each IP. If you haven't set up a geolocation database file, the map file won't be generated.<br>
			                            <b>Output:</b> globe_<ip>.json<br><br>
			
			                            <b>generate_stats()</b> - This will create the horizontal bar graph for the Impact Analysis. 
			                            This will represent the number of inbound, outbound and twoway connections found.<br>
			                            <b>Output:</b> stats-<ip>.json<br><br>
			
			                            <b>generate_dendro()</b> - This function creates a file linking all different IP's that have connected to the IP under investigation, 
			                            this will be displayed in the Storyboard under the Incident Progression panel as a dendrogram.
			                            If no network context file is included, the dendrogram will only be 1 level deep, but if a network context file is included, 
			                            additional levels will be added to the dendrogram to break down the threat activity.<br>
			                            <b>Output:</b> dendro-<ip>.json<br><br>
			
			                             <b>details_inbound()</b> - This function executes a query to the flow table, to find additional details on the IP under investigation and its connections grouping them by time; so the result will be a graph showing the number of connections occurring in a customizable timeframe.<br>
			                            <b>Output:</b> sbdet-<ip>.tsv<br><br>
			
			                            <b>add_threat()</b> - This function updates/creates the threats.csv file, appending a new line for every threat analyzed. 
			                            This file will serve as an index for the Storyboard and is displayed in the 'Executive Threat Briefing' panel.<br>
			                            <b>Output:</b> threats.csv<br><br>
			
			                            Each function will print a message to let you know if its output file was successfully updated.<br><br>
			
			                            <h3>Continue to the Storyboard</h3>
			                            <p>
			                                 Once you have saved comments on any suspicious IP, you can continue to the Storyboard to check the results.
			
			                                <b>Input files</b>
			                                <ul>
			                                    <li>flow_scores.csv</li>
			                                    <li>iploc.csv</li>
			                                    <li>network_context_1.txt</li>
			                                </ul>
			
			                                <b>Output files</b>
			                                <ul>
			
			                                    <li>/oni-oa/data/flow/<date>/threats.csv</li>
			                                    <li>/oni-oa/data/flow/<date>/threat_<ip>.csv</li>
			                                    <li>/oni-oa/data/flow/<date>/sbdet-<ip>.tsv</li> 
			                                    <li>/oni-oa/data/flow/<date>/globe_<ip>.json</li>  
			                                    <li>/oni-oa/data/flow/<date>/stats-<ip>.json</li>  
			                                    <li>/oni-oa/data/flow/<date>/dendro-<ip>.json</li>
			                                </ul>  
			                            </p>
			                           
			                            <b>HDFS tables consumed:</b> flow
			                        </p>
			                    </p>
			                </div>
			                <div id="fsb">
			                    <h3>Storyboard</h3>
			                    <ol>
			                        <li>
			                            Select the option <b>Flow > Storyboard</b> from Apache Spot (incubating) Menu.<br><br>
			                            <img src="images/sb_tit1.JPG"><br><br>
			                        </li>
			                        <li>   
			                            Your view should look something like this, depending on the IP's you have analyzed on the Threat Analysis for that day. 
			                            You can select a different date from the calendar.<br><br>
			                            <img src="images/flow_sb_1.JPG"><br><br>
			                        </li>
			                        <li>
			                            Review the results:<br><br>
			
			                            <b>Executive Threat Briefing</b><br>
			                            <b>Data source file:</b> threats.csv
			                            Executive Threat Briefing lists all the incident titles you entered at the Threat Investigation notebook. 
			                            You can click on any title and the additional information will be displayed.<br><br>
			                            <img src="images/flow_sb_2.JPG" style="width: 50%"><br><br>
			
			                            Clicking on a threat from the list will also update the additional frames.<br><br>
			
			                            <b>Incident Progression</b><br>
			                            <b>Data source file:</b> dendro-<ip>.json<br>
			                            Frame located in the top right of the Storyboard Web page<br><br>
			                            <img src="images/flow_sb_3.JPG"><br><br>
			
			                            Incident Progression displays a tree graph (dendrogram) detailing the type of connections that conform the activity related to the threat. 
			                            When network context is available, this graph will present an extra level to break down each type of connection into detailed context.<br><br>
			
			                            <b>Impact Analysis</b>
			                            <b>Data source file:</b> stats-<ip>.json<br><br>
			                            <img src="images/flow_sb_4.JPG" style="width: 50%"><br><br>
			
			
			                            Impact Analysis displays a horizontal bar graph representing the number of inbound, outbound and two-way connections found related to the threat. 
			                            Clicking any bar in the graph, will break down that information into its context.<br><br>
			
			                            <b>Map View | Globe</b><br>
			                            <b>Data source file:</b> globe_<ip>.json<br><br>
			                            <img src="images/flow_sb_5.JPG" style="width: 50%"><br><br>
			
			                            Map View Globe will only be created if you have a geolocation database. 
			                            This is intended to represent on a global scale the communication detected, 
			                            using the geolocation data of each IP to print lines on the map showing the flow of the data.<br><br>
			
			                            <b>Timeline</b><br>
			                            <b>Data source file:</b> sbdet-<ip>.json<br><br>
			                            <img src="images/flow_sb_6.JPG" style="width: 50%"><br><br>
			
			                            Timeline is created using the resulting connections found during the Threat Investigation process. 
			                            It will display 'clusters' of inbound connections to the IP, grouped by time; 
			                            showing an overall idea of the times during the day with the most activity. 
			                            You can zoom in or out into the graphs timeline using your mouse scroll.<br><br>
			
			                            <b>Input files</b><br><br>
			                            <ul>                    
			                                <li>threats.csv</li>
			                                <li>threat-dendro-${id}.json</li>
			                                <li>stats-${id}.json</li>
			                                <li>globe-${id}.json</li>
			                                <li>sbdet-${id}.tsv</li>
			                            </ul>
			                        </li>
			                    </ol>
			                </div>
			                <div id="fis">
			                    <h3>Ingest Summary</h3>
			                    <ol>
			                        <li>
			                            Load the Ingest Summary page by going to <b>http://"server-ip":8889/files/index_ingest.html </b> or using the drop down menu.<br><br>
			                            <img src="images/is1.png"><br><br>
			                        </li>
			                        <li>
			                            Select a start date, end date and click the reload button to load ingest data. Ingest summary will default to last 7 seven days. 
			                            Your view should now look like this:<br><br>
			                            <img src="images/is2.png"><br><br>
			                        </li>
			                        <li>
			                            Ingest Summary presents the Flows ingestion timeline, showing the total flows for a particular period of time.<br><br>
			                            <ul>
			                                <li>Analyst can zoom in/out on the graph.</li>
			                                <li>Analyst can zoom in/out on the graph.</li>
			                            </ul>
			                        </li>
			                    </ol>
			                </div>
			            </div>
			            <div id="udns">
			                <h2>DNS</h2>
			                <div id="dsc">
			                    <h3>Suspicious DNS</h3>
			                    <ol>
			                        <li>
			                            <b>Open the analyst view for Suspicious DNS:</b> <i>http://"server-ip":8889/files/ui/dns/suspicious.html.</i> Select the date that you want to review (defaults to current date).<br> 
			                            Your screen should now look like this:<br><br>
			                            <img src="images/1.1_dns_sc01.jpg"><br><br>
			                        </li>
			                        <li>
			                            <b>The Suspicious <frame:></frame:></b>
			                            <p>
			                                Located at the top left of the Web page, this frame shows the top 250 suspicious DNS from the Machine Learning (ML) output.<br><br>
			                                <ol>
			                                    <li>By moving the mouse over a suspicious DNS, 
			                                        you will highlight the entire row as well as a blur effect that allows you to quickly identify current connection within the Network View frame.<br><br>
			                                    </li>
			                                    <li>
			                                        Shield icon. Represents the output for any Reputation Services results that has been enabled, user can mouse over in order to obtain additional information. 
			                                        The icon will change its color depending upon the results from specific reputation services.<br><br>
			                                    </li>
			                                    <li>
			                                        By selecting on a Suspicious DNS record, you will highlight current row as well as the node from Network View frame. 
			                                        In addition Details frame will be populated with additional communications directed to the same DNS record.<br><br>
			                                    </li>
			                                </ol>                                          
			                            </p>
			                        </li>
			                        <li>
			                            <b>The Network View frame</b><br><br>
			                            <p>
			                                Located at the top right corner, Network View is a graphic representation of the "Suspicious DNS".<br><br>
			                                <ol>
			                                    <li>As soon as you move your mouse over a node, a dialog shows up providing additional information.<br><br></li>
			                                    <li>Diamonds represents DNS records and circles represents IP addresses communicating to the respective DNS record<br><br></li>
			                                    <li>A primary mouse click in an IP Address (circle) will bring a diagram within Details frame, providing all the Domain Name records queried by that particular IP Address<br><br></li>
			                                    <li>A secondary mouse click uses the node information to filter suspicious data.<br><br></li>
			                                </ol>
			                            </p>
			                        </li>
			                        <li>
			                            <b>The Details frame</b><br><br>
			                            Located at the bottom right corner of the Web page. It provides additional information for the selected connection.<br><br>
			                            Detail View frame has two modes:<br><br>
			                            <ul>
			                                <li>Table details (when you select a record in the Suspicious frame).</li>
			                                <li>Dendrogram diagram (when you select an IP address in the Network View frame)<br><br></li>
			                            </ul>
			                        </li>
			                        <li>
			                            <b>The Notebook frame</b><br>
			                            <p>
			                                This frame contains an initialized Jupyter Notebook. The main function is to allow the Analyst to score IP Addresses and DNS records with different values. In order to assign a risk to a specific connection, select it using a combination of all the combo boxes, select the correct risk rating (1=High risk, 2 = Medium/Potential risk, 3 = Low/Accepted risk) and click Score button. Selecting a value from each list will narrow down the coincidences, therefore if the analyst wishes to score all connections with one same relevant attribute (i.e. ip address 10.1.1.1), then select only the combo boxes that are relevant and leave the rest at the first row at the top.
			                            </p>
			                            <p>
			                                <b>The Score button</b><br><br>
			                                Pressing the 'Score' button will find all exact matches of the selected threat (Client IP or Query) in the dns_scores.csv file and update them with the selected rating value. These results are temporarily stored in the score_tmp.csv file and copied back to the dns_scores.csv file at the end of the process.<br>
			                                Selecting values from both the "Client IP" and "Query" lists to score them together, will update every matching threat individually with the same rating value, but not necessarily as a Client_IP-Query pair.<br><br>
			                                You can score a large set of similar or coincident queries by entering a keyword in the "Quick Scoring" text field and then select a severity value from the radiobutton list. The value entered here will only search for matches on the dns_qry_name name column. "Quick Scoring" text field has precedence over any selection made on the lists.<br>
			                            </p>
			                            <p>
			                                <b>The Save button</b><br><br>
			                                Analysts must use the Save button in order to store the scored records. After you click it, the rest of the frames in the page will be refreshed and the connections that you already scored will disappear on the suspicious connects page. A shell script will be executed to copy the file with the scored connections to the ML Node and specific path. The following values will be obtained from the .conf file:
			                                <ul>
			                                    <li>LPATH</li>
			                                    <li>MLNODE</li>
			                                    <li>LUSER</li>
			                                </ul>
			                            </p>
			                        </li>
			                    </ol>
			                    <b>Input files</b>
			                    <ul>
			                        <li>dns_scores.csv</li>
			                        <li>dns_scores_bu.csv  </li>
			                    </ul>                        
			                </div>
			                <div id="dti">
			                    <h3>DNS Threat Investigation</h3>
			                    Access the analyst view for DNS Suspicious Connects. Select the date that you want to review.<br>
			                    Your view should now look like this:<br><br>
			                    <img src="images/1.1_dns_sc01.jpg"><br><br>
			
			                    The analyst must previously score the suspicious connections before moving into Threat Investigation View, please refer to DNS Suspicious Connects Analyst View walk-through.<br><br>
			                    Select DNS > Threat Investigation from Apache Spot (incubating) Menu.<br><br>
			                    <img src="images/1.1_dns_ti01.jpg"><br><br>
			
			                    Threat Investigation Web Page will be opened, loading the embedded Jupyter notebook. A list with all IPs and DNS Names scored as High risk will be presented<br><br>
			                    <img src="images/1.1_dns_ti02.png"><br><br>
			
			                    <b>Expanded Search</b><br><br>
			
			                    Select any value from the list and press the "Search" button. The system will execute a query to the dns table, 
			                    looking into the raw data initially collected to find additional activity of the selected IP or DNS Name according to the following criteria:<br><br>
			
			                    <b>Expanded Search for a particular Domain Name</b><br>
			                    The query results will provide the different unique IP Addresses list that have queried this particular Domain,
			                    the list will be sorted by the quantity of connections.<br><br>
			                    <img src="images/1.1_dns_ti03.jpg" style="width: 50%;"><br><br>
			
			                    <b>Expanded Search for a particular IP</b><br>
			                    The expanded search will provide the different unique Domains list that this particular IP queried in one day, 
			                    they will be sorted by the quantity of connections made to each specific Domain Name.<br><br>
			                    <img src="images/1.1_dns_ti04.jpg" style="width: 50%;"><br><br>
			
			                    The full output of this query is stored into the threat-dendro-<threat>.csv file, from which the top 'n' results will be extracted and displayed in a table. If an expanded search was previously executed on this IP or Domain, the system will extract the results from the preexisting file to reduce the execution time by avoiding another query to the table. Query execution time is long and will vary depending on whether Hive or Impala is being used, so please monitor the notebooks status icon for completion. The quantity of results displayed on screen can be set by modifying the top_results variable.<br><br>
			
			                    <b>Save comments.</b><br>
			                    In addition, a web form is displayed under the title of 'Threat summary', 
			                    where the analyst can enter a Title & Description on the kind of attack/behavior described by the particular IP address that is under investigation.<br><br>
			                    <img src="images/1.1_dns_ti05.jpg"><br><br>
			
			                    Clicking the "Save" button, will create/update the threats.csv file, adding a new line with the contents of the form. 
			                    This file is used at the Storyboard section to display all the comments entered by the user, 
			                    as well it will serve as a index of the threats analyzed.<br><br>
			
			                    <b>Continue to the Storyboard.</b><br>
			                    Once you have saved comments on any suspicious IP or domain, you can continue to the Storyboard to check the results.<br><br>
			
			                    <b>Input files</b><br>
			                    <ul>
			                        <li>ipython/dns/user/<date>/dns_scores.css</li>
			                    </ul>
			                    
			                    <b>Output files</b>
			                    <ul>
			                        <li>ipython/dns/user/<date>/threats.csv</li>
			                        <li>ipython/dns/user/<date>/threat-dendro-<threat>.csv</li>
			                    </ul>            
			                    
			                    <b>HDFS tables consumed: </b> dns
			
			                </div>
			                <div id="dsb">
			                    <h3>DNS Storyboard</h3>
			                    <b>Walk-through</b><br><br>
			                    <ol>
			                        <li>
			                            Select the option <b>DNS > Storyboard</b> from Apache Spot (incubating) Menu.<br><br>
			                            <img src="images/dns_sb_tit1.jpg"><br><br>
			                        </li>
			                        <li>
			                            Your view should look something like this, 
			                            depending on how many threats you have analyzed and commented on the Threat Analysis for that day. 
			                            You can select a different date from the calendar.<br><br>
			                            <img src="images/1.1_dns_sb01.jpg"><br><br>
			                        </li>
			                    </ol>
			                    <p>
			                        <b>Executive Threat Briefing</b><br>
			                        <b>Data source file:</b> threats.csv<br>
			                        Executive Threat Briefing frame lists all the incident titles you entered at the Threat Investigation notebook. 
			                        You can click on any title and view the additional comments at the bottom area of the panel.<br><br>
			
			                        <b>Incident progression</b>
			                        <b>Data source file:</b> threat-dendro-<threat>.csv<br>
			                        Incident progression frame is located on the right side of the Web page.<br><br>
			                        <img src="images/1.1_dns_sb02.jpg" style="width: 50%;"><br><br>
			
			                        This will display a tree graph (dendrogram) detailing the type of connections that conform the activity related to the threat.<br><br>
			
			                        <b>Input files</b>
			                        <ul>
			                            <li>threats.csv</li>
			                            <li>threat-dendro-<threat>.csv</li>
			                        </ul>                        
			                    </p>
			                </div>
			            </div>
			            <div id="uproxy">
			                <h2>Proxy</h2>
			                <div id="psc">
			                    <h3>Suspicious Proxy</h3>
			                    <b>Walk-through</b>
			                    <ol>
			                        <li>
			                            <b>Open the analyst view for Suspicious Proxy:</b> <i>http://"server-ip":8889/files/ui/proxy/suspicious.html</i>. 
			                            Select the date that you want to review (defaults to current date). <br>
			                            Your screen should now look like this:<br><br>
			                            <img src="images/1.1_proxy_sc01.jpg"><br><br>
			
			                        </li>
			                        <li>
			                            <b>The Suspicious frame</b><br><br>
			                            Located at the top left of the Web page, this frame shows the top 250 Suspicious Proxy connections from the Machine Learning (ML) output.<br><br>
			
			                            <ol>
			                                <li>
			                                    By moving the mouse over a suspicious Proxy record, 
			                                    you will highlight the entire row as well as a blur effect that allows you to quickly identify current connection within the Network View frame.<br><br>
			                                </li>
			                                <li>
			                                    The Shield icon. Represents the output for any Reputation Services results that has been enabled, user can mouse over in order to obtain additional information. 
			                                    The icon will change its color depending upon the results from the Reputation Service.<br><br>
			                                </li>
			                                <li>
			                                    The List icon. When the user mouse over this icon, it presents the Web Categories provided by the Reputation Service<br><br>
			                                </li>
			                                <li>
			                                    By selecting on a Suspicious Proxy record, you will highlight current row as well as the node from Network View frame. In addition, 
			                                    Details frame will be populated with additional communications directed to the same Proxy record.<br><br>
			                                </li>
			                            </ol>                                                    
			                        </li>
			                        <li>
			                            <b>The Network View frame</b><br><br>
			                            Located at the top right corner, Network View is a hierarchical force graph used to represent the "Suspicious Proxy" connections.<br><br>
			
			                            <b>Network View Force Graph Order Hierarchy</b><br><br>
			                            <ul>
			                                <li>Root Proxy Node</li>
			                                <li>Proxy Request Method</li>
			                                <li>Proxy Host</li>
			                                <li>Proxy Path</li>
			                                <li>Client IP Address</li>
			                            </ul><br>
			                            <b>Network View Functionality</b>
			                            <ol>
			                                <li>
			                                    As soon as you move your mouse over a node, a dialog shows up providing additional information.<br><br>
			                                    <img src="images/1.1_proxy_sc02.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    Graph can be zoomed in/out and can be moved in the frame<br><br>
			                                    <img src="images/1.1_proxy_sc03.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    By double-clicking in the Root Proxy Node the graph can be fully expanded/collapsed<br><br>
			                                    <img src="images/1.1_proxy_sc04.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    By double-clicking a node, the node can be expanded/collapsed one level<br><br>
			                                    <img src="images/1.1_proxy_sc05.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    The path in yellow represents the Suspicious record selected in the suspicious frame<br><br>
			                                    <img src="images/1.1_proxy_sc06.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    Records will be highlighted with different colors depending upon the Risk Reputation provided by the Reputation Service<br><br>
			                                    <img src="images/1.1_proxy_sc07.jpg" style="width: 60%;"><br><br>
			                                </li>
			                                <li>
			                                    A secondary mouse click over the Proxy Path or Client IP address nodes populates the Filter Box which eventually filter Suspicious & Network View Frames <br><br>
			                                    <img src="images/1.1_proxy_sc08.jpg" style="width: 60%;"><br><br>
			                                </li>
			                            </ol> 
			                        </li>
			                        <li>
			                            <b>The Details frame</b><br><br>
			                            Located at the bottom right corner of the Web page. It provides additional information for the selected connection in the Suspicious frame. 
			                            It includes columns that are not part of the Suspicious frame such as User Agent, MIME Type, Proxy Server IP, Bytes.<br><br>
			                            <img src="images/1.1_proxy_sc09.jpg" style="width: 60%;"><br><br>
			                        </li>
			                        <li>
			                            <b>The Notebook frame</b><br><br>
			                            This frame contains an initialized Jupyter Notebook. The main function is to allow the Analyst to score Proxy records with different values. In order to assign a risk to a specific connection, select the correct rating (1=High risk, 2 = Medium/Potential risk, 3 = Low/Accepted risk) and click Score button.<br><br>
			                            <img src="images/1.1_proxy_sc10.jpg" style="width: 60%;"><br><br>
			
			                        </li>
			                    </ol>
			
			                    <b>The Score button</b><br><br>
			                    Pressing the 'Score' button will find all exact matches of the selected threat (Proxy Record) in the proxy_scores.csv file and update them with the selected rating value. These results are temporarily stored in the score_tmp.csv file and copied back to the proxy_scores.csv file at the end of the process.<br><br>
			
			                    <b>The Save button</b><br><br>
			                    Analysts must use the Save button in order to store the scored records. After you click it, the rest of the frames in the page will be refreshed and the connections that you already scored will disappear on the suspicious connects page. A shell script will be executed to copy the file with the scored connections to the ML Node and specific path. The following values will be obtained from the .conf file:
			                    <ul>
			                        <li>LPATH</li>
			                        <li>MLNODE</li>
			                        <li>LUSER</li>
			                    </ul>            
			                    
			                    For this process to work correctly, it's important to create an ssh key to enable secure communication between nodes, in this case, the ML node and the node where the UI runs. To learn more on how to create and copy the ssh key, please refer to the "Configure User Accounts" section.<br><br>
			
			                    <b>Input files</b>
			                    <ul>
			                        <li>proxy_scores.csv </li>
			                        <li>proxy_scores_bu.csv</li>
			                    </ul>                 
			                </div>
			                <div id="pti">
			                    <h3>Proxy Threat Investigation</h3>
			                    <b>Walk-through</b><br><br>
			                    Access the analyst view for Proxy Suspicious Connects. Select the date that you want to review. <br>
			                    Your view should now look like this:<br><br>
			                    <img src="images/1.1_proxy_sc01.jpg"><br><br>
			
			                    The analyst must previously score the suspicious connections before moving into Threat Investigation View, please refer to Proxy Suspicious Connects Analyst View walk-through.
			                    Select <b>Proxy > Threat Investigation</b> from Apache Spot (incubating) Menu.<br><br>
			                    <img src="images/1.1_proxy_ti01.jpg"><br><br>
			
			                    Threat Investigation Web Page will be opened, loading the embedded Jupyter notebook. A list with all Proxy Records scored as High risk will be presented<br><br>
			                    <img src="images/1.1_proxy_ti02.jpg" style="width: 60%;"><br><br>
			
			                    <b>Expanded Search</b><br><br>
			
			                    Select any value from the list and press the "Search" button. The system will execute a query to the proxy table, 
			                    looking into the raw data initially collected to find additional activity for the selected Proxy Record. 
			                    Results will be extracted and displayed in a table. If an expanded search was previously executed on this Proxy Record, 
			                    the system will extract the results from the preexisting file to reduce the execution time by avoiding another query to the table. 
			                    Query execution time is long and will vary depending on whether Hive or Impala is being used, so please monitor the notebooks status icon for completion. 
			                    The quantity of results displayed on screen can be set by modifying the top_results variable, 
			                    additional information on how to modify this variable can be found <a href="https://github.com/apache/incubator-spot/blob/master/spot-oa/oa/proxy/ipynb_templates/ThreatInvestigation.md"> here</a><br><br>
			                    <img src="images/1.1_proxy_ti03.jpg" style="width: 60%;"><br><br>
			
			                    <b>Save comments.</b><br><br>
			                    In addition, a web form is displayed under the title of 'Threat summary', 
			                    where the analyst can enter a Title & Description on the kind of attack/behavior described by the particular Proxy Record that is under investigation.<br><br>
			                    <img src="images/1.1_proxy_ti04.jpg" style="width: 60%;"><br><br>
			
			
			                    Clicking the "Save" button, will create/update the threats.csv file, adding a new line with the contents of the form. 
			                    This file is used at the Storyboard section to display all the comments entered by the user, as well it will serve as an index of the threats analyzed.<br><br>
			
			                    <b>Continue to the Storyboard.</b><br>
			                    Once you have saved comments on any suspicious IP or domain, you can continue to the Storyboard to check the results.<br><br>
			
			                    <b>Input files</b>
			                    <ul>
			                        <li>proxy_scores.tsv</li>
			                    </ul>
			
			                    <b>Output files</b>
			                    <ul>
			                        <li>threats.csv</li>
			                        <li>es-{id}.csv</li>
			                        <li>incident-progression-{id}.json</li>
			                        <li>timeline-{id}.tsv</li>
			                    </ul>                
			                    
			                    <b>HDFS tables consumed:</b> proxy
			                </div>
			                <div id="psb">
			                    <h3>Proxy Storyboard</h3>
			                    <ol>
			                        <li>
			                            Select the option <b>Proxy > Storyboard</b> from Apache Spot (incubating) Menu.<br><br>
			                            <img src="images/1.1_proxy_sb01.jpg"><br><br>
			                        </li>
			                        <li>
			                            Your view should look something like this, 
			                            depending on how many threats you have analyzed and commented on the Threat Analysis for that day. 
			                            You can select a different date from the calendar.<br><br>
			                            <img src="images/1.1_proxy_sb02.jpg"><br><br>
			                        </li>
			                    </ol>
			
			                    <b>Executive Threat Briefing</b><br><br>
			                    <b>Data source file:</b> threats.csv<br>
			                    Executive Threat Briefing frame lists all the incident titles you entered at the Threat Investigation notebook. 
			                    You can click on any title and view the additional comments at the bottom area of the panel.<br><br>
			                    <img src="images/1.1_proxy_sb03.jpg" style="width: 50%;"><br><br>
			
			                    <b>Incident progression</b><br><br>
			                    <b>Data source file:</b> incident-progression-{id}.json<br>
			                    Incident progression frame is located on the right side of the Web page.
			                    Incident Progression displays a tree graph (dendrogram) detailing the type of connections that conform the activity related to the threat. 
			                    It presents the following fields:
			                    <ul>
			                        <li><b>Referer</b> - URLs that refers to the Suspicious Proxy Record</li>
			                        <li><b>IP</b> - All ip addresses connecting to the Suspicious Proxy Record</li>
			                        <li><b>Method</b> - Proxy methods used to communicate in between the IP addresses and the Proxy Record</li>
			                        <li><b>ContentType</b> - HTTP MIME Types</li>
			                        <li><b>Threat</b> - Represents the Suspicious Proxy Record</li>
			                        <li><b>Referred</b> - URLs that the Suspicious Proxy Record referred to</li><br>
			                        <img src="images/1.1_proxy_sb04.jpg" style="width: 60%;"><br><br>
			
			                        If multiple IP Addresses connects to a particular Proxy Threat (URL) you can scroll down/up, arrows indicate that there are more elements in the list.<br><br>
			                        <img src="images/1.1_proxy_sb06.jpg" style="width: 60%;"><br><br>
			
			                        <b>Timeline</b><br>
			                        <b>Data source file:</b> timeline-{id}.tsv<br>
			                        Timeline is created using the connections found during the Threat Investigation process. It will display 'clusters' of IP connections to the Proxy Record (URL), grouped by time; showing an overall idea of the times during the day with the most activity. You can zoom in or out into the graphs timeline using your mouse scroll. 
			                        The number next to the IP Address represents the quantity of connections made from that particular IP to the Proxy Record in the displayed time.<br><br>
			                        <img src="images/1.1_proxy_sb05.jpg" style="width: 60%;"><br><br>
			
			                        <b>Input files</b><br><br>
			                        <ul>
			                            <li>threats.csv</li>
			                            <li>incident-progression-{id}.json</li>
			                            <li>timeline-{id}.tsv </li>
			                        </ul>
			                    </ul>
			                </div>
			            </div>
			        </div>
			    </div>            
            </div><!--end main-wrap-->
            
            <div id="more-info">
                <div class="wrap cf">
                    <p class="social-icons">
                        <a href="mailto:info@open-network-insight.org"><span class="icon-envelope"></span></a><a href="https://twitter.com/ApacheSpot" target="_blank"><span class="icon-twitter"></span><a href="http://slack.apache-spot.io/" target="_blank"><img src="images/add-to-slack.png" alt="" class="add-to-slack" /></a></a>
                    </p>

                    <p>
                        <a href="https://github.com/Open-Network-Insight/open-network-insight" class="y-btn" target="_blank">More Info</a>
                    </p>

                    <p style="margin-top:50px;"><img src="images/apache-incubator.png" alt="Apache Incubator" />
                    </p>

                    <p class="disclaimer">
                        Apache Spot is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                    </p>

                    <p class="disclaimer">
                        The contents of this website are © 2016 Apache Software Foundation under the terms of the Apache License v2. Apache Spot and its logo are trademarks of the Apache Software Foundation.
                    </p>
                </div>
            </div>
            
            <footer class="footer">

                <div id="inner-footer" class="wrap cf">

                    <p class="source-org copyright" style="text-align:center;">
                        &copy; 2017 Apache Spot.
                    </p>

                </div>

            </footer>

        </div>
        
		<a href="#0" class="cd-top">Top</a>
		<script type='text/javascript' src='js/classie.js'></script>
        <script type='text/javascript' src='js/scripts.js'></script>

    </body>

</html>
<!-- end of site. what a ride! -->

